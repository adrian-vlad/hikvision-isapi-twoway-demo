<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>capture microphone then show time & frequency domain output</title>

<script src="https://cdn.jsdelivr.net/npm/wavefile"></script>
<script type="text/javascript">

var nodeGain;
var buffers = [];
var bufferLen = 0;


/**
 * @type {number}
 * @private
 */
const BIAS = 0x84;
/**
 * @type {number}
 * @private
 */
const CLIP = 32635;
/**
 * @type {Array<number>}
 * @private
 */
const encodeTable = [
    0,0,1,1,2,2,2,2,3,3,3,3,3,3,3,3,
    4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,
    5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,
    5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,
    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7];
/**
 * Encode a 16-bit linear PCM sample as 8-bit mu-Law.
 * @param {number} sample A 16-bit PCM sample
 * @return {number}
 */
function encodeSample(sample) {
  /** @type {number} */
  let sign;
  /** @type {number} */
  let exponent;
  /** @type {number} */
  let mantissa;
  /** @type {number} */
  let muLawSample;
  /** get the sample into sign-magnitude **/
  sign = (sample >> 8) & 0x80;
  if (sign != 0) sample = -sample;
  /** convert from 16 bit linear to ulaw **/
  sample = sample + BIAS;
  if (sample > CLIP) sample = CLIP;
  exponent = encodeTable[(sample>>7) & 0xFF];
  mantissa = (sample >> (exponent+3)) & 0x0F;
  muLawSample = ~(sign | (exponent << 4) | mantissa);
  /** return the result **/
  return muLawSample;
}

/**
 * Encode 16-bit linear PCM samples into 8-bit mu-Law samples.
 * @param {!Int16Array} samples A array of 16-bit PCM samples.
 * @return {!Uint8Array}
 */
function encode(samples) {
  /** @type {!Uint8Array} */
  let muLawSamples = new Uint8Array(samples.length);
  for (let i=0; i<samples.length; i++) {
    muLawSamples[i] = encodeSample(samples[i]);
  }
  return muLawSamples;
}


function float32To16Bit(input) {
    var result = new ArrayBuffer(input.length * 2);
    var view = new DataView(result);

    for (var i = 0; i < input.length; i++)
    {
        var s = Math.max(-1, Math.min(1, input[i]));
        view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
    
    return new Int16Array(result);
}

var webSocket = new WebSocket("ws://<backend_address>:8765");

var webaudio_tooling_obj = function () {

    var microphone_stream = null;

    if (!navigator.getUserMedia)
        navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
    navigator.mozGetUserMedia || navigator.msGetUserMedia;

    if (navigator.getUserMedia){

        navigator.getUserMedia({audio:true}, 
            function(stream) {
                start_microphone(stream);
            },
            function(e) {
                alert('Error capturing audio.');
            }
            );

    } else { alert('getUserMedia not supported in this browser.'); }

    function start_microphone(stream){
        const readablestream = new ReadableStream({
            start(controller) {
                var audioContext = new AudioContext({latencyHint: "interactive", sampleRate: 8000});
                console.log("audio is starting up ...");
                
                microphone_stream = audioContext.createMediaStreamSource(stream);

                window.scriptNode = audioContext.createScriptProcessor(4096, 1, 1);
                window.scriptNode.onaudioprocess = function(audioProcessingEvent) {
                    buf = new Float32Array(audioProcessingEvent.inputBuffer.getChannelData(0));
                    buffers.push(buf);
                    bufferLen += buf.length;
                    console.log(audioProcessingEvent.inputBuffer);
                    controller.enqueue(buf);
                    webSocket.send(encode(float32To16Bit(buf)));
                };
                
                microphone_stream.connect(window.scriptNode);
                window.scriptNode.connect(audioContext.destination);
                
                const close = document.querySelector('.close');
                close.onclick = null;
                close.addEventListener('click', function() {
                    stream.getTracks()[0].stop();
                    window.scriptNode.disconnect();
                    microphone_stream.disconnect();
                    audioContext.close();
                    console.log("buffers");
                    console.log(buffers);
                    
                    b = new Float32Array(bufferLen);
                    var offset = 0;
                    for (var i = 0; i < buffers.length; i++){
                        b.set(buffers[i], offset);
                        offset += buffers[i].length;
                    }
                    console.log(b);
                    
                    controller.enqueue(null);
                });
                console.log("audio started");
            }
        });
    }

};

</script>

</head>
<body>

    <button class="close">Close stream</button>
    <p> </p>
    <button onclick="webaudio_tooling_obj()">start audio</button>

</body>
</html>
